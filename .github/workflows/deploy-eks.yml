# .github/workflows/deploy-eks.yml
name: Deploy EKS Cluster with OpenTofu

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'terraform/**'
      - '.github/workflows/deploy-eks.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'terraform/**'
      - '.github/workflows/deploy-eks.yml'
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'plan'
        type: choice
        options:
        - plan
        - apply
        - destroy
      confirm_apply:
        description: 'Type "yes" to confirm apply/destroy action'
        required: false
        default: 'no'
        type: string
      cluster_name:
        description: 'Override cluster name (optional)'
        required: false
        type: string

env:
  AWS_REGION: us-east-1
  CLUSTER_NAME: my-eks-cluster
  TF_VERSION: 1.6.6
  TOFU_VERSION: 1.6.0
  # Optional: override bucket name (leave empty for auto-generation)
  STATE_BUCKET_NAME: ""

jobs:
  setup-state-backend:
    name: Setup State Backend
    runs-on: ubuntu-latest
    outputs:
      bucket-name: ${{ steps.create-bucket.outputs.bucket-name || steps.use-existing-bucket.outputs.bucket-name }}
      dynamodb-table: ${{ steps.create-dynamodb.outputs.table-name || steps.use-existing-dynamodb.outputs.table-name }}
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Generate bucket name
      id: generate-name
      run: |
        # Use custom bucket name if provided, otherwise generate from repo info
        if [ -n "${{ env.STATE_BUCKET_NAME }}" ]; then
          BUCKET_NAME="${{ env.STATE_BUCKET_NAME }}"
          echo "Using custom bucket name: ${BUCKET_NAME}"
        else
          # Create predictable bucket name based on repo and owner
          REPO_NAME=$(echo "${GITHUB_REPOSITORY}" | cut -d'/' -f2 | tr '[:upper:]' '[:lower:]')
          OWNER_NAME=$(echo "${GITHUB_REPOSITORY_OWNER}" | tr '[:upper:]' '[:lower:]')
          
          # Create stable bucket name
          BUCKET_NAME="tofu-state-${OWNER_NAME}-${REPO_NAME}"
          echo "Generated bucket name: ${BUCKET_NAME}"
        fi
        
        # Ensure it's valid (lowercase, no underscores, etc.)
        BUCKET_NAME=$(echo $BUCKET_NAME | sed 's/[^a-z0-9-]/-/g' | sed 's/--*/-/g')
        
        echo "bucket-name=${BUCKET_NAME}" >> $GITHUB_OUTPUT
        echo "dynamodb-table=${BUCKET_NAME}-lock" >> $GITHUB_OUTPUT
        echo "Final bucket name: ${BUCKET_NAME}"

    - name: Check if S3 bucket exists
      id: check-bucket
      run: |
        BUCKET_NAME="${{ steps.generate-name.outputs.bucket-name }}"
        
        # Check if bucket exists and is accessible
        if aws s3api head-bucket --bucket $BUCKET_NAME 2>/dev/null; then
          echo "exists=true" >> $GITHUB_OUTPUT
          echo "âœ… Bucket $BUCKET_NAME already exists and is accessible"
        else
          echo "exists=false" >> $GITHUB_OUTPUT
          echo "ğŸ“¦ Bucket $BUCKET_NAME does not exist, will create"
        fi

    - name: Create S3 bucket for Terraform state
      id: create-bucket
      if: steps.check-bucket.outputs.exists == 'false'
      run: |
        BUCKET_NAME="${{ steps.generate-name.outputs.bucket-name }}"
        
        # Create bucket with region-specific logic
        if [ "${{ env.AWS_REGION }}" = "us-east-1" ]; then
          # us-east-1 doesn't require LocationConstraint
          aws s3api create-bucket \
            --bucket $BUCKET_NAME \
            --region ${{ env.AWS_REGION }}
        else
          # All other regions require LocationConstraint
          aws s3api create-bucket \
            --bucket $BUCKET_NAME \
            --region ${{ env.AWS_REGION }} \
            --create-bucket-configuration LocationConstraint=${{ env.AWS_REGION }}
        fi
        
        # Wait a moment for bucket to be fully created
        sleep 5
        
        # Verify bucket was created
        if aws s3api head-bucket --bucket $BUCKET_NAME 2>/dev/null; then
          echo "âœ… Successfully created S3 bucket: $BUCKET_NAME"
        else
          echo "âŒ Failed to verify bucket creation"
          exit 1
        fi
        
        # Enable versioning
        aws s3api put-bucket-versioning \
          --bucket $BUCKET_NAME \
          --versioning-configuration Status=Enabled
        
        # Block public access
        aws s3api put-public-access-block \
          --bucket $BUCKET_NAME \
          --public-access-block-configuration "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
        
        # Enable encryption
        aws s3api put-bucket-encryption \
          --bucket $BUCKET_NAME \
          --server-side-encryption-configuration '{
            "Rules": [
              {
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }
            ]
          }'
        
        echo "bucket-name=${BUCKET_NAME}" >> $GITHUB_OUTPUT

    - name: Use existing bucket
      id: use-existing-bucket
      if: steps.check-bucket.outputs.exists == 'true'
      run: |
        BUCKET_NAME="${{ steps.generate-name.outputs.bucket-name }}"
        echo "bucket-name=${BUCKET_NAME}" >> $GITHUB_OUTPUT
        echo "â™»ï¸ Reusing existing S3 bucket: $BUCKET_NAME"
        
        # Verify bucket configuration
        echo "Checking bucket configuration..."
        aws s3api get-bucket-versioning --bucket $BUCKET_NAME || echo "Versioning status unknown"
        aws s3api get-bucket-encryption --bucket $BUCKET_NAME || echo "Encryption status unknown"

    - name: Check if DynamoDB table exists
      id: check-dynamodb
      run: |
        TABLE_NAME="${{ steps.generate-name.outputs.dynamodb-table }}"
        if aws dynamodb describe-table --table-name $TABLE_NAME 2>/dev/null; then
          echo "exists=true" >> $GITHUB_OUTPUT
        else
          echo "exists=false" >> $GITHUB_OUTPUT
        fi

    - name: Create DynamoDB table for state locking
      id: create-dynamodb
      if: steps.check-dynamodb.outputs.exists == 'false'
      run: |
        TABLE_NAME="${{ steps.generate-name.outputs.dynamodb-table }}"
        
        aws dynamodb create-table \
          --table-name $TABLE_NAME \
          --attribute-definitions AttributeName=LockID,AttributeType=S \
          --key-schema AttributeName=LockID,KeyType=HASH \
          --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5
        
        # Wait for table to be active
        aws dynamodb wait table-exists --table-name $TABLE_NAME
        
        echo "table-name=${TABLE_NAME}" >> $GITHUB_OUTPUT
        echo "ğŸ”’ Created DynamoDB table: $TABLE_NAME"

    - name: Use existing DynamoDB table
      id: use-existing-dynamodb
      if: steps.check-dynamodb.outputs.exists == 'true'
      run: |
        TABLE_NAME="${{ steps.generate-name.outputs.dynamodb-table }}"
        echo "table-name=${TABLE_NAME}" >> $GITHUB_OUTPUT
        echo "â™»ï¸ Reusing existing DynamoDB table: $TABLE_NAME"

  plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    needs: setup-state-backend
    if: |
      github.event_name == 'pull_request' || 
      (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'plan') ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main')
    
    steps:
    - name: Validate manual confirmation
      if: github.event_name == 'workflow_dispatch'
      run: |
        if [ "${{ github.event.inputs.action }}" = "apply" ] && [ "${{ github.event.inputs.confirm_apply }}" != "yes" ]; then
          echo "âŒ Apply action requires confirmation. Please set 'confirm_apply' to 'yes'"
          echo "This safety check prevents accidental infrastructure changes."
          exit 1
        fi
        echo "âœ… Manual confirmation validated"

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup OpenTofu
      uses: opentofu/setup-opentofu@v1
      with:
        tofu_version: ${{ env.TOFU_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Download plan artifact (optional)
      uses: actions/download-artifact@v4
      with:
        name: terraform-plan
        path: terraform/
      continue-on-error: true

    - name: Set cluster name
      id: set-cluster-name
      run: |
        if [ -n "${{ github.event.inputs.cluster_name }}" ]; then
          CLUSTER_NAME="${{ github.event.inputs.cluster_name }}"
          echo "Using custom cluster name: $CLUSTER_NAME"
        else
          CLUSTER_NAME="${{ env.CLUSTER_NAME }}"
          echo "Using default cluster name: $CLUSTER_NAME"
        fi
        echo "cluster-name=${CLUSTER_NAME}" >> $GITHUB_OUTPUT

    - name: Create backend configuration
      run: |
        cat > terraform/backend.tf << EOF
        terraform {
          backend "s3" {
            bucket         = "${{ needs.setup-state-backend.outputs.bucket-name }}"
            key            = "eks-cluster/terraform.tfstate"
            region         = "${{ env.AWS_REGION }}"
            dynamodb_table = "${{ needs.setup-state-backend.outputs.dynamodb-table }}"
            encrypt        = true
          }
        }
        EOF

    - name: Terraform Init
      working-directory: ./terraform
      run: tofu init

    - name: Terraform Validate
      working-directory: ./terraform
      run: tofu validate

    - name: Terraform Plan
      working-directory: ./terraform
      run: |
        tofu plan \
          -var="cluster_name=${{ env.CLUSTER_NAME }}" \
          -var="region=${{ env.AWS_REGION }}" \
          -out=tfplan

    - name: Upload plan artifact
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan
        path: terraform/tfplan
        retention-days: 5
        compression-level: 6

  apply:
    name: Terraform Apply
    runs-on: ubuntu-latest
    needs: [setup-state-backend, plan]
    if: |
      (github.ref == 'refs/heads/main' && github.event_name == 'push') ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply')
    environment: 
      name: production
      url: ${{ steps.cluster-info.outputs.cluster-endpoint }}
    
    steps:
    - name: Validate destroy confirmation
      run: |
        if [ "${{ github.event.inputs.confirm_apply }}" != "yes" ]; then
          echo "âŒ Destroy action requires confirmation. Please set 'confirm_apply' to 'yes'"
          echo "âš ï¸  This will permanently delete your EKS cluster and all associated resources!"
          echo "ğŸ’¡ To confirm, run the workflow again with confirm_apply set to 'yes'"
          exit 1
        fi
        echo "âœ… Destroy confirmation validated"
        echo "âš ï¸  Proceeding with cluster destruction..."

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup OpenTofu
      uses: opentofu/setup-opentofu@v1
      with:
        tofu_version: ${{ env.TOFU_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Create backend configuration
      run: |
        cat > terraform/backend.tf << EOF
        terraform {
          backend "s3" {
            bucket         = "${{ needs.setup-state-backend.outputs.bucket-name }}"
            key            = "eks-cluster/terraform.tfstate"
            region         = "${{ env.AWS_REGION }}"
            dynamodb_table = "${{ needs.setup-state-backend.outputs.dynamodb-table }}"
            encrypt        = true
          }
        }
        EOF

    - name: Terraform Init
      working-directory: ./terraform
      run: tofu init

    - name: Terraform Apply
      working-directory: ./terraform
      run: |
        tofu apply \
          -var="cluster_name=${{ steps.set-cluster-name.outputs.cluster-name }}" \
          -var="region=${{ env.AWS_REGION }}" \
          -auto-approve

    - name: Get cluster info
      id: cluster-info
      working-directory: ./terraform
      run: |
        CLUSTER_ENDPOINT=$(tofu output -raw cluster_endpoint)
        CLUSTER_NAME=$(tofu output -raw cluster_id)
        echo "cluster-endpoint=${CLUSTER_ENDPOINT}" >> $GITHUB_OUTPUT
        echo "cluster-name=${CLUSTER_NAME}" >> $GITHUB_OUTPUT

    - name: Configure kubectl
      run: |
        aws eks --region ${{ env.AWS_REGION }} update-kubeconfig --name ${{ steps.cluster-info.outputs.cluster-name }}

    - name: Test cluster connectivity
      run: |
        kubectl cluster-info
        kubectl get nodes

    - name: Create deployment summary
      run: |
        echo "## ğŸš€ EKS Cluster Deployment Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Resource | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
        echo "| Cluster Name | ${{ steps.cluster-info.outputs.cluster-name }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Cluster Endpoint | ${{ steps.cluster-info.outputs.cluster-endpoint }} |" >> $GITHUB_STEP_SUMMARY
        echo "| AWS Region | ${{ env.AWS_REGION }} |" >> $GITHUB_STEP_SUMMARY
        echo "| State Bucket | ${{ needs.setup-state-backend.outputs.bucket-name }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Configure kubectl locally:" >> $GITHUB_STEP_SUMMARY
        echo '```bash' >> $GITHUB_STEP_SUMMARY
        echo "aws eks --region ${{ env.AWS_REGION }} update-kubeconfig --name ${{ steps.cluster-info.outputs.cluster-name }}" >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY

  destroy:
    name: Terraform Destroy
    runs-on: ubuntu-latest
    needs: setup-state-backend
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'destroy'
    environment: 
      name: production-destroy
      url: "Destroying EKS cluster and all resources"
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup OpenTofu
      uses: opentofu/setup-opentofu@v1
      with:
        tofu_version: ${{ env.TOFU_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Create backend configuration
      run: |
        cat > terraform/backend.tf << EOF
        terraform {
          backend "s3" {
            bucket         = "${{ needs.setup-state-backend.outputs.bucket-name }}"
            key            = "eks-cluster/terraform.tfstate"
            region         = "${{ env.AWS_REGION }}"
            dynamodb_table = "${{ needs.setup-state-backend.outputs.dynamodb-table }}"
            encrypt        = true
          }
        }
        EOF

    - name: Terraform Init
      working-directory: ./terraform
      run: tofu init

    - name: Terraform Destroy
      working-directory: ./terraform
      run: |
        tofu destroy \
          -var="cluster_name=${{ env.CLUSTER_NAME }}" \
          -var="region=${{ env.AWS_REGION }}" \
          -auto-approve

    - name: Cleanup state backend (optional)
      if: github.event.inputs.cleanup_backend == 'true'
      run: |
        echo "âš ï¸ Cleaning up state backend resources..."
        
        # Empty and delete S3 bucket
        aws s3 rm s3://${{ needs.setup-state-backend.outputs.bucket-name }} --recursive
        aws s3api delete-bucket --bucket ${{ needs.setup-state-backend.outputs.bucket-name }}
        
        # Delete DynamoDB table
        aws dynamodb delete-table --table-name ${{ needs.setup-state-backend.outputs.dynamodb-table }}
        
        echo "ğŸ—‘ï¸ State backend resources cleaned up"